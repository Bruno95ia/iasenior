# ðŸŽ¯ Guia Completo de Treinamento de DetecÃ§Ã£o de Quedas

Sistema completo para treinar modelo YOLOv8 customizado usando seus prÃ³prios vÃ­deos.

## âœ… Status Atual

- âœ… **963 frames extraÃ­dos** dos 8 vÃ­deos
- âœ… Sistema de anotaÃ§Ã£o criado
- âœ… Pipeline de treinamento pronto
- âœ… IntegraÃ§Ã£o com sistema principal

## ðŸš€ Passo a Passo RÃ¡pido

### 1. Anotar Frames (OBRIGATÃ“RIO)

**ðŸŽ¯ Escolha o mÃ©todo mais rÃ¡pido para vocÃª:**

#### âš¡ MÃ©todo RÃ¡pido (Recomendado - Mais Veloz)
```bash
streamlit run datasets/quedas/anotar_rapido.py
```
- âš¡ Modo turbo: 2-3 segundos por frame
- ðŸ¤– DetecÃ§Ã£o automÃ¡tica de pessoas
- ðŸ“‹ Reutiliza Ãºltima bbox
- âŒ¨ï¸ Atalhos: Setas (navegar), EspaÃ§o (prÃ³ximo), Q (marcar queda)
- **Velocidade: ~200-300 frames/hora**

#### ðŸ¤– MÃ©todo Inteligente (Recomendado - Mais Preciso)
```bash
streamlit run datasets/quedas/anotar_quedas_inteligente.py
```
- ðŸ¤– IA detecta pessoas e sugere bboxes automaticamente
- âœ… BotÃ£o "Usar SugestÃ£o" com 1 clique
- ðŸ“‹ PropagaÃ§Ã£o automÃ¡tica para frames prÃ³ximos
- ðŸ” Filtro para mostrar sÃ³ frames com pessoas
- **Velocidade: ~100-150 frames/hora**

#### ðŸŽ¬ MÃ©todo por VÃ­deo (Mais RÃ¡pido para VÃ­deos Longos)
```bash
streamlit run datasets/quedas/anotar_por_video.py
```
- â±ï¸ Marque inÃ­cio/fim das quedas no vÃ­deo (nÃ£o frame a frame!)
- ðŸ“Š Timeline visual interativa
- ðŸŽ¯ Gera anotaÃ§Ãµes automaticamente para todos os frames do intervalo
- **Velocidade: ~10-20 quedas/hora (mas cada queda = muitos frames!)**
- **Exemplo:** 3 intervalos = 300 frames anotados em minutos!

#### ðŸ“ MÃ©todo Manual (Original)
```bash
streamlit run datasets/quedas/anotar_quedas.py
```
- Interface completa com todas as opÃ§Ãµes
- Controle total sobre cada frame

**ðŸ’¡ Dica:** Use o script interativo para escolher:
```bash
./datasets/quedas/iniciar_anotacao.sh
```

**ðŸ“š Veja [ESCOLHER_METODO.md](datasets/quedas/ESCOLHER_METODO.md) para comparar mÃ©todos**

### 2. Preparar Dataset

```bash
cd datasets/quedas
python3 preparar_dataset.py
```

Isso divide em:
- **70% treino** (para aprender)
- **20% validaÃ§Ã£o** (para ajustar)
- **10% teste** (para avaliar)

### 3. Treinar Modelo

```bash
# OpÃ§Ã£o 1: Script completo (recomendado)
./datasets/quedas/treinar_completo.sh

# OpÃ§Ã£o 2: Manual
cd datasets/quedas
python3 treinar_modelo.py --epochs 100 --batch 16 --validar
```

**ParÃ¢metros:**
- `--epochs 100`: NÃºmero de Ã©pocas (mais = melhor, mas demora mais)
- `--batch 16`: Batch size (aumente se tiver GPU)
- `--device cuda`: ForÃ§ar GPU (se disponÃ­vel)
- `--validar`: Validar apÃ³s treinamento

**Tempo estimado:**
- CPU: 4-8 horas
- GPU: 30-60 minutos

### 4. Usar Modelo Treinado

O sistema detecta automaticamente o modelo em `modelos/queda_custom.pt` e usa ele!

## ðŸ“Š Estrutura de Arquivos

```
datasets/quedas/
â”œâ”€â”€ videos/                    # âœ… Seus 8 vÃ­deos aqui
â”œâ”€â”€ frames/                    # âœ… 963 frames extraÃ­dos
â”‚   â””â”€â”€ frames_index.json
â”œâ”€â”€ annotations/               # ðŸ“ AnotaÃ§Ãµes (criar aqui)
â”‚   â”œâ”€â”€ images/              # Imagens anotadas
â”‚   â”œâ”€â”€ labels/              # Labels YOLO (.txt)
â”‚   â””â”€â”€ anotacoes.json       # JSON com anotaÃ§Ãµes
â”œâ”€â”€ dataset_yolo/            # ðŸ“¦ Dataset preparado
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ test/
â”‚   â””â”€â”€ dataset.yaml
â””â”€â”€ modelos_treinados/        # ðŸŽ“ Modelo treinado
    â””â”€â”€ queda_custom.pt
```

## ðŸŽ¯ Dicas de AnotaÃ§Ã£o

### Boas PrÃ¡ticas

1. **Anote bem as bounding boxes**
   - Inclua toda a pessoa caÃ­da
   - NÃ£o corte partes importantes
   - Seja consistente

2. **Diversidade Ã© importante**
   - Diferentes Ã¢ngulos
   - Diferentes iluminaÃ§Ãµes
   - Diferentes tipos de queda

3. **Anote tambÃ©m negativos**
   - Frames SEM quedas sÃ£o importantes
   - Marque "Tem queda" = false nesses casos

4. **Qualidade > Quantidade**
   - 50 frames bem anotados > 200 mal anotados
   - Foque em qualidade primeiro

### Exemplo de Bounding Box

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”‚  â† Bounding box deve incluir
â”‚   â”‚ QUEDA â”‚     â”‚     toda a pessoa caÃ­da
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ˆ MÃ©tricas Esperadas

ApÃ³s treinamento, vocÃª verÃ¡:

- **mAP50**: PrecisÃ£o mÃ©dia (objetivo: >0.80)
- **mAP50-95**: PrecisÃ£o em mÃºltiplos IoU (objetivo: >0.60)
- **Precision**: PrecisÃ£o (objetivo: >0.85)
- **Recall**: Recall (objetivo: >0.80)

### InterpretaÃ§Ã£o

- **mAP50 > 0.8**: Modelo muito bom! âœ…
- **mAP50 0.6-0.8**: Modelo bom, pode melhorar
- **mAP50 < 0.6**: Precisa mais dados/treinamento

## ðŸ”§ Troubleshooting

### "Nenhum frame encontrado"
```bash
cd datasets/quedas
python3 extrair_frames.py
```

### "Nenhuma imagem encontrada"
Execute a anotaÃ§Ã£o primeiro:
```bash
streamlit run datasets/quedas/anotar_quedas.py
```

### Modelo nÃ£o melhora

1. **Adicione mais dados**
   - Mais vÃ­deos de quedas
   - Mais anotaÃ§Ãµes

2. **Melhore anotaÃ§Ãµes**
   - Verifique qualidade das bounding boxes
   - Anote mais frames negativos

3. **Ajuste parÃ¢metros**
   - Aumente Ã©pocas: `--epochs 200`
   - Aumente batch: `--batch 32` (se tiver GPU)

### GPU nÃ£o detectada

```bash
# Verificar PyTorch
python3 -c "import torch; print(torch.cuda.is_available())"

# ForÃ§ar CPU
python3 treinar_modelo.py --device cpu
```

## ðŸš€ PrÃ³ximos Passos ApÃ³s Treinamento

1. **Testar em vÃ­deos novos**
   ```bash
   python3 datasets/quedas/inferencia_quedas.py videos/novo_video.mp4
   ```

2. **IntegraÃ§Ã£o automÃ¡tica**
   - Modelo em `modelos/queda_custom.pt` Ã© usado automaticamente
   - Sistema detecta e usa modelo customizado

3. **Melhorar continuamente**
   - Adicione mais vÃ­deos
   - Re-treine com mais dados
   - Ajuste thresholds

## ðŸ’¡ Dicas AvanÃ§adas

### Transfer Learning

O modelo usa YOLOv8n como base (jÃ¡ treinado em milhÃµes de imagens). Isso acelera muito o treinamento!

### Data Augmentation

YOLO aplica automaticamente:
- RotaÃ§Ã£o
- Flip
- MudanÃ§a de brilho
- Zoom

### Fine-tuning

ApÃ³s treinar, vocÃª pode:
- Ajustar confidence threshold
- Treinar mais Ã©pocas
- Usar modelo maior (yolov8s.pt, yolov8m.pt)

## ðŸ“š Recursos

- [DocumentaÃ§Ã£o YOLOv8](https://docs.ultralytics.com/)
- [Formato YOLO](https://docs.ultralytics.com/datasets/)
- [Guia de Treinamento](https://docs.ultralytics.com/modes/train/)

---

**Pronto para comeÃ§ar? Execute:**
```bash
./datasets/quedas/iniciar_anotacao.sh
```

